<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Development | Sansa's Site</title><link>https://summmeer.github.io/tag/development/</link><atom:link href="https://summmeer.github.io/tag/development/index.xml" rel="self" type="application/rss+xml"/><description>Development</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 30 Sep 2021 00:00:00 +0000</lastBuildDate><image><url>https://summmeer.github.io/media/icon_hu4465e7aec766cd42246149649a25868d_28750_512x512_fill_lanczos_center_3.png</url><title>Development</title><link>https://summmeer.github.io/tag/development/</link></image><item><title>Iwenbooks Development</title><link>https://summmeer.github.io/project/iwen/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/iwen/</guid><description>&lt;p>Iwen is a book and news reading APP, which currently provides service for more than 20,000 users. Many useful modules are implemented in this APP which help users to better understand the reading materials, for example, the TTS(text-to-speech), auto-translation, auto-question-generation and so on.&lt;/p>
&lt;p>Besides the role of CTO and team management. I mainly responsible for the back-end development, the database maintenance and the implementation of recommendation algorithm.&lt;/p>
&lt;ul>
&lt;li>Design the database structure for the news/user data and develop API for the front-end.&lt;/li>
&lt;li>Implement the vanilla book/news recommendation system, which is based on a hybrid strategy combining collaborative filtering and user portraits. For books, I consider content information like the abstract and timeliness of books in the users&amp;rsquo; history to model users&amp;rsquo; interests. For news, I summarize the topic that each user may be interested in and adjust the recommendation score personalizely for them in real time.&lt;/li>
&lt;/ul></description></item><item><title>A Search Engine from scratch based on the WikiPedia data</title><link>https://summmeer.github.io/project/wing/</link><pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/wing/</guid><description>&lt;p>Wikipedia is a well-known free online encyclopedia, created and edited by volunteers around the world, and it offers free copies of all available content, where we can get the latest complete dump of the English-language Wikipedia. Thus, we build a Wikipedia-based search engine: Wing, with 5 sort algorithms, a well-designed GUI, and the responsive time scale of millisecond. Wing is short for ``Wing Is Not Google&amp;rsquo;'.&lt;/p>
&lt;p>After we download the 17GB zip file of the whole raw data and unzip it, we use a Wiki-Extractor tool to extract around 10 million documents. We use SPIMI (Single-Pass In-Memory Indexing) algorithm to construct a posting list.&lt;/p>
&lt;h3 id="algorithm-optimize">Algorithm Optimize&lt;/h3>
&lt;p>TF-IDF based methods will give short articles high weights. So, there will be a problem that some docs whose content is very short but not very relative to the query, have high weights in ranking results. Thus, when we calculate the term frequency, we increase the term frequency of the words that appear in the title. Through this way, we can filter some short but meaningless docs and get what we want.&lt;/p>
&lt;p>We optimized TF-IDF with PageRank score, which is computed to measure the authority of pages.&lt;/p>
&lt;h3 id="developemnt">Developemnt&lt;/h3>
&lt;p>We adopt Flask to enable our back end. Flask is a microframework for web applications written in Python. The front end is implemented with Vue. Vue is a progressive framework for building user interfaces. Also, we use Element UI, a desktop component library, to make our interface more beautiful and user-friendly. The front end includes three pages: welcome page, query page, and article page. It is well known that Python program is running as a single process and is very slow. To speed up our program written by Python, we use Multiprocess package to accelerate our for-loop.&lt;/p></description></item></channel></rss>
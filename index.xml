<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sansa's Site</title><link>https://summmeer.github.io/</link><atom:link href="https://summmeer.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Sansa's Site</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate><image><url>https://summmeer.github.io/media/icon_hu4465e7aec766cd42246149649a25868d_28750_512x512_fill_lanczos_center_3.png</url><title>Sansa's Site</title><link>https://summmeer.github.io/</link></image><item><title>Example Talk</title><link>https://summmeer.github.io/talk/example-talk/</link><pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate><guid>https://summmeer.github.io/talk/example-talk/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click on the &lt;strong>Slides&lt;/strong> button above to view the built-in slides feature.
&lt;/div>
&lt;/div>
&lt;p>Slides can be added in a few ways:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> slides using Wowchemy&amp;rsquo;s &lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">&lt;em>Slides&lt;/em>&lt;/a> feature and link using &lt;code>slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Upload&lt;/strong> an existing slide deck to &lt;code>static/&lt;/code> and link using &lt;code>url_slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Embed&lt;/strong> your slides (e.g. Google Slides) or presentation video on this page using &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">shortcodes&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Further event details, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">page elements&lt;/a> such as image galleries, can be added to the body of this page.&lt;/p></description></item><item><title>Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation</title><link>https://summmeer.github.io/publication/newsrec/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/publication/newsrec/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>Supplementary notes can be added here, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">code, math, and images&lt;/a>.&lt;/p></description></item><item><title>Survey list of diffusion models</title><link>https://summmeer.github.io/post/getting-started/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/post/getting-started/</guid><description>&lt;h3 id="classical-model-unconditional">Classical model (unconditional)&lt;/h3>
&lt;ol>
&lt;li>Diffusion original&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Jascha Sohl-Dickstein et al. “Deep Unsupervised Learning using Nonequilibrium Thermodynamics.” ICML 2015.&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>NCSN and NCSNv2 (noise-conditioned score network)
Score-based generative modeling + Langevin dynamics&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Yang Song &amp;amp; Stefano Ermon. “Generative modeling by estimating gradients of the data distribution.” NeurIPS 2019.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Yang Song &amp;amp; Stefano Ermon. “Improved techniques for training score-based generative models.” NeurIPS 2020. (for higher resolution)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>DDPM&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Jonathan Ho et al. “Denoising diffusion probabilistic models.” NeurlPS 2020.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Alex Nichol &amp;amp; Prafulla Dhariwal. “ Improved denoising diffusion probabilistic models” ICML 2021. (ImageNet)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="4">
&lt;li>DDIM non- Markov chain to speed up&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Jiaming Song et al. “Denoising diffusion implicit models.” ICLR 2021.&lt;/li>
&lt;/ul>
&lt;h3 id="domain">Domain&lt;/h3>
&lt;ol>
&lt;li>Image&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Prafula Dhariwal &amp;amp; Alex Nichol. &amp;ldquo;Diffusion Models Beat GANs on Image Synthesis.&amp;rdquo; NeurIPS 2021.&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>Time series&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Yang Song, CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation, NeurIPS, 2021&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>Text&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Nikolay Savinov, Aaron van den Oord. &amp;ldquo;Step-unrolled Denoising Autoencoders for Text Generation.&amp;rdquo; ICLR 2022. [SUNDAE code non-official] (baseline: Disco, CMLM)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Emiel Hoogeboom Max Welling. &amp;ldquo;Argmax flows and multinomial diffusion: Towards non-autoregressive language models.&amp;rdquo; NeurIPS 2021. [code1, code2] (image+text)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Jacob Austin, Rianne van den Berg. &amp;ldquo;Structured denoising diffusion models in discrete state-spaces.&amp;rdquo; NeurIPS 2021. [D3PM code] (image+text)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AUTOREGRESSIVE DIFFUSION MODELS. ICLR 2022&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Diffusion-LM Improves Controllable Text Generation&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="4">
&lt;li>Speech&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Gautam Mittal, Ian Simon. &amp;ldquo;Symbolic music generation with diffusion models.&amp;rdquo; ISMIR 2021. (SMG)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis&lt;/p>
&lt;/li>
&lt;li>
&lt;p>WaveGrad: Estimating Gradients for Waveform Generation. ICLR 2021&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="5">
&lt;li>text2img&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Chitwan Saharia. &amp;ldquo;Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding&amp;rdquo;. [non-official code]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Aditya Ramesh, Mark Chen. &amp;ldquo;Hierarchical Text-Conditional Image Generation with CLIP Latents&amp;rdquo;.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>KNN-Diffusion: Image Generation via Large-Scale Retrieval&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="compare-text-generation">Compare Text Generation&lt;/h3>
&lt;ol>
&lt;li>AR vs NAR:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>ARDM uses order-agnostic AR (parallelized)
NAR: multinomial diffusion, D3PM, SUNDAE, SMG, Diffusion-LM&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>Continuous vs discrete:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>ARDM, D3PM, SUNDAE is discrete (clear transition)
Diffusion-LM is continuous, SMG first uses VAE to encode&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>Controllable:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Diffusion-LM uses plug and play&lt;/li>
&lt;li>WaveGrad uses condition with diffusion model&lt;/li>
&lt;li>CSDI: condition on input sequence&lt;/li>
&lt;/ul></description></item><item><title>Dynamic Product Categorization for Multiple Domain</title><link>https://summmeer.github.io/project/productcate/</link><pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/productcate/</guid><description>&lt;p>Product categorization is to assign a product with a suitable category, which is usually organized in a predefined taxonomy. As e-commerce platforms developing different business lines, a special but challenging categorization scenario emerges, where there are multiple domain-specific category taxonomies and each of them evolves dynamically over time.&lt;/p>
&lt;p>In order to unify the categorization process and jointly utilize the cross-domain data, we propose a two-stage taxonomy-agnostic framework that relies solely on calculating the semantic relatedness between product titles and category names in the vector space.&lt;/p>
&lt;p>However, pure vector matching may fall for the surface form of text, and we thus further leverage the universal “knowledge” across different business domains to complement textual semantics. We design a heuristic retrieval strategy and pretrain a contrastive ranking model with the help of “concept”, which resembles the shared keyword knowledge cross domains.&lt;/p>
&lt;p>Our comprehensive experiments show that our method outperforms existing sophisticated approaches quantitatively and efficiently on dynamical multi-domain taxonomies.&lt;/p></description></item><item><title>Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation</title><link>https://summmeer.github.io/project/newsrec/</link><pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/newsrec/</guid><description>&lt;p>In this paper, we are interested in exploiting user actions outside the clicks themselves. We call them &amp;ldquo;implicit feedback&amp;rdquo;. Typical implicit feedback can be extracted from browsing the main page, reading an article, closing an article, backtracking, etc. We believe that modeling such implicit feedback &amp;ldquo;explicitly&amp;rdquo; in the session-based recommendation system can help the recommender understand user intention better. In this work, we focus on answering these questions:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>If a user clicked an article, did she really like it?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If a user did not click an article, did she dislike it?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>How do we model the temporal characteristics of the user and the articles in the system?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>First, in traditional recommendation systems, “clicks” usually indicate a “like” or a vote from the user, but things are a bit different for news reading. Users may be “tricked” into clicking an article and once they realize that, they will quickly back out and switch to other articles. Thus the time a user spends on reading an article article, than just the click alone, which is only binary. We model this as the implicit positive feedback in this paper.&lt;/p>
&lt;p>Second, just because the user did not click on an article does not necessarily mean the user does not like it; maybe she was never exposed to this article!We can infer what articles might have an impression on the user during a session by by assuming that articles are presented to the user roughly in the order of their publication time. Only those articles within her list of impressions but not clicked are considered &amp;ldquo;not interesting&amp;rdquo; to her. This is called implicit negative feedback.&lt;/p>
&lt;p>Finally, while the positive and negative feedback helps us estimate the connection between the user and articles, some critical temporal information is useful to model the user and the articles individually. The session start time of a user may suggest the daily routine of that user. We can expect users who read on the same day of a week or same time of a day to have to share the same reading behavior or even background. On the other hand, the publishing time of each article can also be formed into a sequence in a session, which reflects the user’s sensitivity of the timeliness of the stories. We thus carefully design the representation of session start time and article publishing time as implicit neutral feedback.&lt;/p></description></item><item><title>Iwenbooks Development</title><link>https://summmeer.github.io/project/iwen/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/iwen/</guid><description>&lt;p>Iwen is a book and news reading APP, which currently provides service for more than 20,000 users. Many useful modules are implemented in this APP which help users to better understand the reading materials, for example, the TTS(text-to-speech), auto-translation, auto-question-generation and so on.&lt;/p>
&lt;p>Besides the role of CTO and team management. I mainly responsible for the back-end development, the database maintenance and the implementation of recommendation algorithm.&lt;/p>
&lt;ul>
&lt;li>Design the database structure for the news/user data and develop API for the front-end.&lt;/li>
&lt;li>Implement the vanilla book/news recommendation system, which is based on a hybrid strategy combining collaborative filtering and user portraits. For books, I consider content information like the abstract and timeliness of books in the users&amp;rsquo; history to model users&amp;rsquo; interests. For news, I summarize the topic that each user may be interested in and adjust the recommendation score personalizely for them in real time.&lt;/li>
&lt;/ul></description></item><item><title>A Search Engine from scratch based on the WikiPedia data</title><link>https://summmeer.github.io/project/wing/</link><pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/project/wing/</guid><description>&lt;p>Wikipedia is a well-known free online encyclopedia, created and edited by volunteers around the world, and it offers free copies of all available content, where we can get the latest complete dump of the English-language Wikipedia. Thus, we build a Wikipedia-based search engine: Wing, with 5 sort algorithms, a well-designed GUI, and the responsive time scale of millisecond. Wing is short for ``Wing Is Not Google&amp;rsquo;'.&lt;/p>
&lt;p>After we download the 17GB zip file of the whole raw data and unzip it, we use a Wiki-Extractor tool to extract around 10 million documents. We use SPIMI (Single-Pass In-Memory Indexing) algorithm to construct posting list.&lt;/p>
&lt;h3 id="algorithm-optimize">Algorithm Optimize&lt;/h3>
&lt;p>TF-IDF based methods will give short articles high weights. So, there will be a problem that some docs that their content is very short but not very relative to the query, have high weights in ranking results. Thus, when we calculate the term frequency, we increase the term frequency of the words that appear in the title. Through this way, we can filter some short but meaning less docs and get what we want.&lt;/p>
&lt;p>We optimized TF-IDF with PageRank score, which is computed to measure the authority of pages.&lt;/p>
&lt;h3 id="developemnt">Developemnt&lt;/h3>
&lt;p>We adopt Flask to enable our back end. Flask is a microframework for web appliction written in Python. Front end is implemented with Vue. Vue is a progressive framework for building user interfaces. Also, we use Element UI, a desktop component library, to make our interface more beautiful and user-friendly. Front end includes three pages: welcome page, query page, and article page. It is well known that Python program is running as a single process and is very slow. To speed up our program written by Python, we use Multiprocess package to accelerate our for-loop.&lt;/p></description></item><item><title/><link>https://summmeer.github.io/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://summmeer.github.io/admin/config.yml</guid><description/></item></channel></rss>